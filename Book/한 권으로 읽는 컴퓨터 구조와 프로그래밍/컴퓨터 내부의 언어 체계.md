#CS

언어는 정보소통을 위한 매개체이다. 프로그래머가 컴퓨터에 명령을 내리기 위해서는 컴퓨터가 이해할 수 있는 언어가 필요하다. 따라서 사람이 컴퓨터의 말을 배워야한다. 자연어는 수천년 지화해온 결과이다. 컴퓨터 언어는 최근에 만들어진 인공적인 발명품으로 자연어를 사용해 컴퓨터 언어를 설명할 수 있다.

# 언어란 무엇인가.
언어는 편의를 제공하기 위한 지름길이다. 언어를 사용하면 복잡한 개념을 직접 보여주지 않고도 의사소통을 할 수 있다.
모든 언어의 뜻은 기호의 집합으로 인코딩된다. 언어가 제대로 작동 하려면 의사소통 당사자들이 같은 문맥을 공유해서 같은 기호에 같은 의미를 부여할 수 있어야한다. 언어나 문맥을 명확히 해석할 수 있는 것은 아니다. 이는 컴퓨터 언어에서도 마찬가지이다.

# 문자 언어
문자 언어는 기호를 나열한 것이다. 기호와 조합은 무궁무진한 가능성이 있다. 언어의 순서도 다를 수 있다. 다음의 세가지 요소가 문자 언어의 틀을 이루는데 컴퓨터 언어에서도 마찬가지이다.
- 기호가 들어갈 상자
- 상자에 들어갈 기호
- 상자의 순서

# 비트
자연어에서는 이 상자를 문자라고 부르고 컴퓨터에서는 비트(bit)라고 부른다. 비트는 2진법을 의미하는 binary와 숫자를 뜻하는 digit가 합쳐진 말이다.
비트는 2진법을 사용한다.
기호라는 개념은 추상적이다. 실제로는 기호가 무엇이든 관계 없다. (참/거짓, O/X, 1/0)

# 논리연산
비트 사용법 중 하나는 예/아니오 질문에 대한 답을 표현하는 것이다. '파티장소는 어디인가?' 같은 질문은 예/아니오 로 대답할 수 없으므로 하나의 비트만으로는 표현할 수 없다.
자연어에서는 여러 예/아니오 구절을 엮어서 한 문장으로 나타내는 경우가 있다. 예를 들어 '밖에 비가 오거나 춥다면 코트를 입어라' 이 경우 '비가 오는가' 가 참이거나 '추운가' 가 참이면 '코트를 입는다' 가 참이 된다. 이럲게 다른 비트들이 표현하는 내용으로 새로운 비트를 만들어 내는 것을 논리 연산이라 한다.

## 불리언 대수
불리언 대수(boolean algebra)는 비트에 대해서 사용할 수 있는 연산 규칙의 집합이다. 결합법칙, 분배법칙, 교환법칙이 사용 가능하다.
- NOT: 논리적 반대
- AND: 둘 이상의 비트에 작용, 모든 비트가 참인 경우에만 연산 결과가 참이 된다.
- OR: 둘 이상의 비트에 작용, 하나의 비트라도 참인 경우 참이 된다.
- XOR(exclusive OR): 두 비트의 값이 다른 경우에만 참이 된다.

## 드모르간의 법칙
a AND b = NOT(NOT a OR NOT b) 가 드모르간의 법칙이다. 이는 NOT을 충분히 사용하면 AND 연산을 OR 연산을 대신할 수 있다는 뜻이 된다. 긍정적인 논리에 대해 부정적인 논리를 기술하는 명제를 사용할 때, 드모르간의 법칙을 활용할 수 있다. 부논리에 다른 연산을 적용하는 것으로 정논리와 같게 동작하게 할 수 있다. 이는 NOT을 추가하는 것을 줄여주므로 연산량을 줄여준다. 이것으로 비용과 연산 시간이 감소될 수 있다.

# 정수를 비트로 표현하는 법
## 양의 정수 표현
수의 값은 각 상자에 든 내용물의 값과 상자의 값을 곱한 것을 모두 더한 값이다. 상자의 값은 밑이 무엇이냐에 따라 다르다. 10진법의 경우 10, 2진법의 경우 2가 된다. 비트를 사용해 수를 표현하는 경우 0과 1만 사용할 수 있으므로 밑이 2인 2진법 수체계가 된다.
10진수의 숫자 개수는 표현할 수 있는 값의 법위를 결정한다 2개면 $10^2$ 개 (0 ~ 99) 2 진수에서도 비트의 개수가 표현할 수 있는 값의 범위를 결정한다. 2비트면 $2^2$ (0 ~ 3) 
2진수에서 가장 오른쪽 비트를 가장 작은 유효 비트(least significant bit, LSB)라고 하고, 가장 왼쪽의 비트를 가장 큰 유효 비트(most significant bit, MSB)라고 한다.
수를 표기할 때,  leading zero를 추가하여 더 많은 수로 표현을 해도 같은 수가 된다. 컴퓨터는 미리 정해진 수의 비트를 한 덩어리로 사용하도록 만들어졌기 때문에 2진수를 쓸 때, 이런 식으로 항상 일정한 개수의 비트를 사용해 값을 표현하는 경우가 종종 있다.

## 2진수 덧셈
LSB에서 MSB쪽으로 차례대로 더하여 결과가 1보다 크면 다음 자리로 올린다. 이때 논리 연산을 통해 2진 산술 연산을 수행할 수 있다.
두 비트를 서로 더한 결과는 XOR 연산 결과와 같고 올림은 AND 연산 결과와 같다.
덧셈의 결과가 사용할 비트의 개수로 표현할 수 있는 범위를 벗어나면 overflow가 발생한다고 한다.
overflow는 MSB에서 올림이 발생한 경우를 뜻한다.
MSB 위쪽에서 1을 빌려오는 경우를 underflow라고 한다.

## 음수 표현
4비트로는 16가지가 표현 가능하므로 0부터 15까지를 표현할 수 있다. 그러나 꼭 이렇게 할 필요는 없다. 새로운 문맥을 만들 수도 있다는 것이다.
부호표현을 하나의 비트로 대체한다. MSB를 부호로 사용하기로 한다. 4비트의 경우 -7 ~ +7 의 15가지 수를 표현할 수 있다.(+0 == -0) 이러한 표현법을 부호와 크기(sign and significant) 표현법이라고 한다. 이 표현법은 두 가지 이유로 널리 쓰이지 못한다.
1. 0을 표현하는 방법이 두 가지라서 비용낭비가 발생한다.
2. XOR과 AND를 통한 덧셈계산이 불가능하다.
	- +1과 -1을 더하는 경우 0이 아닌 -2가 된다.
좀 더 복잡한 로직을 적용해서 부호와 크기 표현법에 대한 연산을 만들 수도 있다. 하지만 모든 것을 간단하게 유지하는 편이 더 가치있다.

### 1의 보수
음수를 표현하는 다른 방법으로 양수의 모든 비트를 뒤집는 방법이 있다. 이런 방법을 1의 보수라고 한다.(one's complement) 1의 보수 표현법에서도 부호와 크기 표현법과 비슷하게 비트를 부호비트와 나머지로 나눈다. 0111(+7)을 뒤집으면 1000(-7)을 얻을 수 있다. 하지만 여전히 0을 두 가지 방법으로 표현하는 문제가 있다. (0000, 1111) 또한 덧셈도 복잡하다. MSB에 올림이 발생한 경우에 LSB로 올림을 전달하는 순환올림(end-around carry)를 사용해야 한다.

### 2의 보수
+1에 더했을 때 0이 나오는 비트패턴을 찾고 이 패턴을 -1이라고 하자. 4비트에서 +1은 0001이고 1111 을 더하면 0이 되므로 1111이 -1이 된다. 이러한 표현법을 2의 보수(two's complement)라고 한다. 어떤 수의 비트를 뒤집고 1을 추가하면 음수를 얻을 수 있다. MSB에서 올림이 발생하면 이 값은 버린다.

같은 표현이라도 문맥에 따라 값이 달라질 수 있음을 인지하자. 1111은 2의 보수에서는 -1이고 부호와 크기에서는 -7이고 1의 보수에서는 -0이다.

# 실수를 표현하는 방법
밑이 2인 경우 실수를 표기하기 위해 2진 소수점을 표현할 방법이 필요하다.

## 고정소수점 표현법
고정소수점(fixed point)는 2진 소수점의 위치를 임의로 정하는 방법이다. 4비트의 경우 2비트는 2진 소수점 오른쪽에 있는 비트들로 분수를 표현하는데 쓰고 왼쪽 비트들은 숫자를 표현하는데 쓴다. 이렇게하면 소수점의 위치가 항상 일정하다. 그러나 쓸모 있는 범위의 실수 값을 표현하기 위해 필요한 비트의 개수가 너무 많다는 단점이 있다. 아보가드로 수 처럼 매우 큰 수를 표현하는 경우 몇백 비트가 필요한데, 모든 수를 수백 비트로 표현할 수는 없다.

## 부동소수점 표현법
과학적 표기법을 2진수에 적용한 방법으로 밑이 10이 아닌 2일 뿐이다. 과학적 표기법은 소수점 왼쪽이 한자리 뿐인 소수(가수)에 10을 몇번(지수)거듭제곱하는 방식으로 소수를 표현한다.  그래도 부동소수점도 비효율성이 있다. 
- 비트 조합 중에서 낭비되는 부분이 많다. 0을 표현하는 방법이 많고, (가수가 0이기만 하면 된다.) 가수와 지수의 조합에 따라 표현은 다르나 동일한 수를 가리키는 경우가 있다.
- 비트 패턴이 모든 수를 표현하지는 못한다. 지수가 커질 수록 가수의 한 패턴과 다른 패턴 사이의 값 차이가 커지게 된다. 따라서 중간 수를 표현하지 못하는 경우가 생기게 된다.

## IEEE 부동소수점 수 표준
더 많은 비트를 사용하고 가수와 지수에 대해 각각 부호 비트를 사용한다. 지수에 대한 부호 비트는 지수의 비트 패턴에 감춰져 있다. 낭비되는 비트 조합을 최소화하고 반올리믕 쉽게 하기 위한 여러 트릭을 사용한다. 똑같은 비트를 사용하더라도 정밀도를 높이려고 한다. 이때 사용하는 방법은 정규화이다.
정규화는 가수를 조정해서 맨 앞에 0이 없게 만든다. 이때 지수 또한 조정해야 한다. 그리고 가수의 맨 왼쪽 비트가 1인 것을 알고 있으므로 이를 생략한다. 이것으로 비트를 하나 더 사용할 수 있게 된다.
두 가지 부동소수점 수가 주로 사용된다.
1. 기본 정밀도(single precision): 32 비트 사용, 7비트 정밀도, $\pm10^{\pm38}$ 정도 범위 표현
2. 2배 정밀도(double precision): 64 비트 사용, 15비트 정밀도, $\pm10^{\pm308}$ 정도 범위 표현
두 형태 모두 가수에 대한 부호를 사용한다. 지수는 부호가 없으나 편향된 지수 값을 사용한다. 기본 정밀도의 경우 편향값은 127로 127(01111111)이 지수 .을 표현한다. 1(00000001)이 지수에서는 -126을 표현하고 254(11111110)가 +127을 표현한다.

# 2진 코드화한 10진수 시스템
BCD(binary-coded decimal) 4비트를 사용해 10진 숫자를 하나 표현한다. 더이상 주류에 남아있지는 않으나 마주치는 경우가 있다. 2 진수를 효율적으로 활용하지 못하므로 인기가 적어졌다. 비트 낭비가 큰 요소이다.

# 2진수를 다루는 쉬운 방법
## 8진 표현법
octal representation은 2진수 비트들을 3개씩 그룹으로 묶는 아이디어이다.

## 16진 표현법
hexadecimal representation은 2진수 비트들을 4개씩 그룹으로 묶는 아이디어이다. 요즘은 컴퓨터 내부가 8비트의 배수로 만들어지므로 주로 사용한다. 8의 배수는 4로는 나누어 떨어지지만 3으로는 균일하기 나눠지지 않기 때문이다. 0 ~ 15를 0~9 와 a~f 로 표현한다.

## 프로그래밍 언어의 진법 표기법
아래 첨자를 사용하여 진법을 나타내는 것은 불편하므로 대부분의 프로그래밍 언어는 다음 방법을 사용한다.
- `0` 으로 시작하는 경우 : 8진수
- `1~9`로 시작하는 경우 : 10진수
- `0x` 로 시작하는 경우 : 16진수

# 비트 그룹의 이름
컴퓨터를 설계하는 사람은 비용을 고려하여 컴퓨터가 사용하는 비트의 개수와 비트들의 조직을 결정해야 한다. 비트는 너무 작아서 기본 단위로 사용하기에는 유용성이 떨어진다. 8비트 덩어리가 기본 단위로 널리 쓰이기 시작했고 이를 바이트(byte)라고 부른다.
| 이름       | 비트 개수 |
| ---------- | --------- |
| nibble     | 4         |
| byte       | 8         |
| halfword   | 16        |
| word       | 32        |
| doubleword | 64        |
워드는 각 컴퓨터가 설계상 자연스럽게 사용할 수 있는 비트 묶음들의 크기이다. 자연스럽게 쓸 수 있다는 말은 컴퓨터가 빠르게 처리할 수 있는 가장 큰 덩어리를 뜻한다. C나 C++ 등의 언어에서 `int`라고 선언한 변수가 이런 자연스러운 크기의 2진수를 표현한다.
일반적으로 사용되는 kilo, mega, giga 등의 의미는 10을 밑으로 하는 표현이 맞다. 이후 사용되는 KiB, MiB, GiB 등은 1000과 가까운 $2^{10}=1024$ 을 의미한다.

# 텍스트 표현
## 아스키 코드
ASCII(Americal Standard Code for Information Interchage): 키보드에 있는 모든 기호에 대해 7비트 수 값을 할당했다. 예를들어 65는 A, 66은 B. 이외에도 장치를 제어하기 위해 쓰이는 제어 문자들도 있다. 상당수는 통신제어를 위한 문자이다.

## 다른 표준의 진화
다른 언어 지원의 필요성이 증가함에 따라서 다른 표준들도 생겨나게 되었다. ISO-646과 ISO-8859이 도입되었다. 이는 유럽 언어에 필요한 액센트 기호나 발음 구별 기호를 추가한 표준이다. 이후 다른 언어 문화권에 대해서도 표준들이 추가 되었다. 각기 다른 표준이 존재하는 이유는 비트가 지금보다 더 비싼 시절에 표준이 만들어졌기 때문이다. 비트 가격이 떨어지면서 유니코드라는 새로운 표준이 생겼고 처음에는 16비트를 부여했다. 그러나 이후 21비트까지 확장되었다. 

## 유니코드 변환 형식 8비트
아스키 코드의 경우 8비트로 모든 문자를 표현할 수 있는데 16비트를 사용하는 것은 낭비이므로 8비트로 표현한다. 유니코드는 이 문제를 문자 코드마다 다른 인코딩을 적용해 해결한다. 인코딩은 다른 비트 패턴을 표현하기 위해 사용하는 비트패턴을 말한다. 우리는 비트 같은 추상화를 사용해 숫자를 표현하고, 숫자로 문자를 표현하고, 다른 숫자를 사용해 이런 문자를 표현하는 숫자를 표현한다.
UTF-8(Unicode Transformation Format-8bit)라는 인코딩 방법이 가낭 널리 쓰인다. UTF-8은 모든 아스키 문자를 8bit로 표현하기 때문에 아스키 데이터를 인코딩할 때는 추가 공간이 필요하지 않다. 그리고 UTF-8은 아스키가 아닌 문자의 경우 아스키를 받아서 처리하는 프로그램이 깨지지 않는 방법으로 문자를 인코딩한다. UTF-8은 문자를 8비트 덩어리의 시퀀스로 인코딩한다. 첫 번째 덩어리의 MSB쪽에 있는 비트들이 8비트 덩어리 시퀀스의 길이를 표현하고 덩어리의 맨 앞을 식별하기 쉽다. 프로그램이 문자 경계를 찾아야하는 경우 이런 특성이 유용하다. 문자가 7비트를 넘는 경우 쪼개어 담는다.

# 문자를 사용한 수 표현
UTF-8은 문자(예:A)를 표현하는 비트들(2진수 0000000001000001)로 부터 나온 숫자들 (0x)
##  출력 가능하게 변경한 인코딩
## 베이스64 인코딩
## URL인코딩
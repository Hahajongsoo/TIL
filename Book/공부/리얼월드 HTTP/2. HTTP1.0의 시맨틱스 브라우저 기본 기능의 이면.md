앞 장에서 HTTP의 기본 네 요소를 설명했다.
- 메서드와 경로
- 헤더
- 바디
- 스테이터스 코드
브라우저가 기본 요소들을 어떻게 응용하고 기본 기능을 실현하는지 살펴본다.
# 1 단순한 폼 전송(x-www-form-urlencoded)
HTTP/1.0의 바디 수신은 클라이언트가 지정한 콘텐츠가 그대로 저장될 뿐이다. 기본적으로 한 번 HTTP가 응답할 때마다 한 파일밖에 반환하지 못하기 때문이다. 즉 응답의 본체를 지정한 바이트 수만큼 읽어오면 그만이다. 
폼을 사용한 `POST` 전송에는 몇 가지 방식이 있다. 가장 단순한 전송 방식은 다음과 같다.
```HTML
<form method="POST">
	<input name="title">
	<input name="author">
	<input name="submit">
</form>
```
일반적인 웹에서 볼 수 있는 폼이며 method에는 `POST`가 설정돼 있다. 다음처럼 curl 커맨드를 사용하면 폼과 같은 형식으로 전송할 수 있다.
```shell
$ curl --http1.0 -d title="The Art of Community" -d author="Jono Bacon" http://localhost:8080
```
curl 커맨드는 `-d`옵션이 지정도미ㅕㄴ 브라우저와 똑같이 헤더로 `Content-Type:application/x-www-form-urlencoded`를 설정한다. 이때 바디는 키와 값이 `=`로 연결되고, 각 항목이 `&`로 연결된 문자열이 된다.
```
title=The Art of Community&author=Jono Bacon
```
실제로는 이 커맨드가 생성하는 바디는 브라우저의 웹 폼에서 전송하는 것과는 약간 차이가 있다. curl에서는 실제 보내는 데이터에 구분문자인 `&`와 `=`가 들어있는 경우 그대로 연결해버린다. 브라우저는 RFC 1866에서 책정한 변환 포맷에 따라 변환을 실시한다. 이 포맷에서는 알파벳, 수치, 별표, 하이픈, 마침표, 언더스코어의 여섯 종류 문자 외에는 변환이 필요하다.
```
title=Head+First+PHP+%26+MySQL&author=Lynn+Beighley%2C+Michael+Morrison
```
curl에는 이와 가까운 기능을 하는 `data-urlencode`가 있다. 이때 RFC 3986에서 정의된 방법으로 변환된다.
웸 폼의 GET의 경우 바디가 아니라 쿼리로서 URL에 부여된다고 RFC 1866에 정의되어 있다.

# 2 폼을 이용한 파일 전송
HTML의 폼에서는 옵션으로 멀티파트 폼 형식이라는 인코딩 타입을 선택할 수 있다. 옵션을 사용해서 파일을 보낼 수 있다. RFC 1867에 정의돼 있다. 
```
<form action="POST" enctype="multipart/form-data">
</form>
```
보통 HTTP 응답은 한 번에 한 파일씩 반환하므로, 빈 줄을 찾아 그곳부터 `Content-Length`로 지정된 바이트 수만큼 읽기만 하면 데이터를 통째로 가져올 수 있다. 하지만 멀티파트를 이용하는 경우는 한 번의 요청으로 복수의 파일을 전송할 수 있으므로 받는 쪽에서 파일을 나눠야 한다.
다음은 크롬 브라우저의 멀티파트 폼 형태로 출력했을 때의 헤더이다. 경계 문자열인 하나의 속성이 추가적으로 부여돼있다.
```
Content-Type: multipart/form-data; boundary=---WebKitFormBoundaryy0YfbccgoID172j7
```
바디는 다음과 같이 경계 문자열로 두 개의 블록으로 나뉜 것을 알 수 있다. 각각의 블록 내부도 HTTP와 같은 구성으로, 헤더+빈 줄+콘텐츠로 되어있다. 헤더에는 `Content-Disposition` 이라는 항목이 포함된다. Disposition은 기질, 성질이란 뜻으로, 대체로 `Content-Type`과 같은 것이다. 여기서는 항목의 이름을 붙이고 폼의 데이터라고 선언했다.
```
------WebKitFormBoundaryy0YfbccgoID172j7
Content-Disposition: form-data; name="title"

The Art of Community
------WebKitFormBoundaryy0YfbccgoID172j7
Content-Disposition: form-data; name="author"

Jono Bacon
------WebKitFormBoundaryy0YfbccgoID172j7--
```
여러 줄인 `X-www-form-urlencoded`와 다를 바 없지만 파일을 전송해보면 다르다.
```
<input name="attachment-file" type="file"
```
이 폼을 전송하면 다음과 같은 결과가 표시된다. `multipart/form-data`는 항목마다 추가 메타정보를 태그로 가질 수 있다. 파일을 전송할 때 이름, 파일명, 파일 종류, 그리고 파일 내용이라는 세 가지 정보가 전송되는 것을 알 수 있다. `x-www-form-urlencoded`는 파일 전송에 필요한 정보를 모두 보낼 수 없어, 파일 이름만 전송해버린다.
```
------WebKitFormBoundaryy0YfbccgoID172j7
Content-Disposition: form-data; name="attachment-file"; filename="test.txt"
Content=type: text/plain

hello world

------WebKitFormBoundaryy0YfbccgoID172j7--
```
`-F`를 사용하면 curl 커맨드는 `enctype="multipart/form-data`가 설정된 폼과 같은 형식으로 송신한다. `-d`와 `-F`를 섞어 쓸 수는 없다. 
```
#파일 내용을 test.txt에서 취득. 파일명은 로컬 파일명과 같다. 형식도 자동 설정.
$ curl --http1.0 -F attachment-file@test.txt http://localhost:8080

#파일 내용을 test.txt에서 취득. 형식은 수동 설정.
$ curl --http1.0 -F "attachment-file@test.txt;type=text/html" http://localhost:8080

#파일 내용을 test.txt에서 취득. 파일명은 지정한 파일명을 이용.
$ curl --http1.0 -F "attachment-file@test.txt;filename=sample.txt" http://localhost:8080
```
# 3 폼을 이용한 리디렉트
스테이터스 코드를 사용한 리디렉트의 경우 몇 가지 제한이 있다.
- URL에는 2000자 이내라는 기준이 있어 `GET`의 쿼리로 보낼 수 있는 데이터양에 한계가 있다.
- 데이터가 URL에 포함되므로, 전송하는 내용이 액세스 로그 등에 남을 우려가 있다.
이런 문제를 피하고자 종종 이용되는 방법이 HTML의 폼을 이용한 리디렉트이다. 서버로부터는 리디렉트할 곳으로 보내고 싶은 데이터가 `<input type="hidden">` 태그로 기술된 HTML이 되돌아 온다. 폼에서 보내는 곳이 리디렉트할 곳이다. 브라우저가 이 HTML 을 열면 로드 직후 발생하는 이벤트로 폼을 전송하므로 즉시 리디렉트해 이동하게 된다.
순간적으로 빈 페이지가 표시된다는 점과 전환 버튼이 표시되긴 하지만 자바스크립트가 비활성화 되어 있으면 자동으로 전환되지 않는다는 단점이 있다.

# 4 콘텐트 니고시에이션
서버와 클라이언트는 따로 개발되므로 양쪽이 기대하는 형식이나 설정이 항상 일치할 수는 없다. 통신 방법을 최적화하고자 하나의 요청 안에서 서버와 클라이언트가 서로 최고의 설정을 공유하는 시스템이 콘텐트 니고시에이션이다. 콘텐트 니고시에이션에는 헤더를 이용한다. 

| 요청 헤더           | 응답                           | 니고시에이션 대상 |
| --------------- | ---------------------------- | --------- |
| Accept          | Content-Type 헤더              | MIME 타입   |
| Accept-Language | Content-Language 헤더/ html 태그 | 표시 언어     |
| Accept-Charset  | Content-Type 헤더              | 문자의 문자셋   |
| Accept-Encoding | Content-Encoding 헤더          | 바디 압축     |
## 4.1 파일 종류 결정
```
Accept: text/html,application/xhtml,xml,application/xml;q=0.9,image/webp,*/*;q=0.8
```
구글 크롬의 요청 헤더에서 가져왔다. 이미지 항목에 집중해 설명한다. 우선 콤마로 항목을 나눈다.
- `image/webp`
- `*/*;q=0.8`
q는 품질 계수라는 것으로 0에서 1까지의 수치로 설정한다. 기본은 1.0이고 이때는 q가 생략된다. 이 수치는 우선순위를 나타낸다. 웹 서버가 Webp(구글이 권장하는 PNG보다 20%파일 크기가 작아지는 이미지 형식)을 지원하면 Webp를 , 그렇지 않으면 PNG등 다른 포맷(우선순위0.8)을 서버에 보낼 것을 요구하고 있다.
서버는 요청에서 요구한 형식 중에서 파일을 반환한다. 우선순위를 해석해 위에서부터 차례로 지원하는 포맷을 찾고, 일치하면 그 포맷으로 반환한다. 만약 서로 일치하는 형식이 없으면 서버가 `406 Not Acceptable` 오류를 반환한다.
## 4.2 표시 언어 결정
클라이언트가 지원하는 언어 종류를 나타낸다. 표시 언어도 기본은 같다.
```
Accept-Language: en-US,en;=0.8,ko;q=0.6
```
다시 말해, `en-US`, `en`, `ko` 라는 우선 순위로 요청ㅇ르 보낸다. 언어 정보를 담는 상자로서 `Content-Language` 헤더가 있지만, 대부분 이 헤더는 사용하지 않는 것 같다. 다음과 같이 HTML 태그 안에서 반환하는 페이지를 많이 볼 수 있다.
```html
<html lang="ko">
```

## 4.3 문자셋 결정
어느 모던 브라우저도 `Accept-Charset`을 송신하지 않는다. 아마도 브라우저가 모든 문자셋 인코더를 내장하고 있어, 미리 니고시에이션할 필요가 없어졌기 때문으로 여겨진다. 문자셋은 MIME 타입과 세트로 `Content-Type` 헤더에 실려 통지된다.
```
Content-Type: text/html; charset=UTF-8
```
HTML의 경우 문서 안에 쓸 수도 있다. 이 방식은  RFC 1866의 HTML/2.0으로 이미 이용할 수 있다. HTML을 로컬에 저장했다가 다시 표시하는 경우도 많으므로, 이 방식도 함께 많이 사용한다.
```
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
```
HTML의 `<meta http-equiv>` 태그는 HTTP 헤더와 똑같은 지시를 내려 문서 내부에 삽입해서 반환하는 상자이다. HTML5에서는 다음과 같이 표기할 수도 있다.
```
<meta charset="UTF-8">
```

## 4.4 압축을 이용한 통신 속도 향상
콘텐츠 압축은 전송 속도 향상을 위한 것이다. 콘텐츠 내용에 따라 다르지만, 현재 일반적으로 사용되는 압축 알고리즘을 적용하면 텍스트 파일은 1/10 크기로 압축된다. 통신에 걸리는 시간보다 압축과 해제가 짧은 시간에 이루어지므로, 압축을 함으로써 웹페이지를 표시할 때 걸리는 전체적인 처리 시간을 줄일 수 있다.
콘텐츠 압축 니고시에이션은 모두 HTTP의 헤더 안에서 완료한다. 우선 클라이언트가 수용 가능한 압축 방식을 헤더에서 지정한다.
```
Accept-Encoding: deflate, gzip
```
curl 커맨드에서 `--compressed` 옵션을 지정하면 `-H` 옵션으로 위 헤더를 기술한 것과 같다.
서버는 전송받은 목록 중 지원하는 방식이 있으면, 응답할 때 그 방식으로 압축하거나 미리 압축된 콘텐츠를 반환한다. 서버가 gzip을 지원하면, 조금 전에 받은 요청에 대한 응답으로 다음과 같은 헤더가 부여된다.
```
Content-Encoding: gzip
```
서버가 지원하지 않으면 양쪽에서 다 지원하는 다른 인코딩으로 대체된다. 이처럼 HTTP 헤더라는 틀을 이용해 한 번의 왕복의 짧은 요청과 응답 속에서 하위 호환성을 유지하면서도 서로 최적의 통신을 할 수 있게 시스템이 정비됐다.
흔히 압축 알고리즘(슬라이드 사전)은 파일의 일부와 'x 바이트 앞의 내용을 여기에 x바이트 만큼 전개한다'라는 지시를 함께 저장한다. '경기도안양시안양동안안양아트센터'라는 문자열은 다음처럼 된다.
```
경기도안양시[3글자 앞에서 2글자 복사]동[3글자 앞에서 2글자 복사]아트센터
```
# 5 쿠키
쿠키란 웹사이트의 정보를 브라우저 쪽에서 저장하는 작은 파일이다. 일반적으로 DB는 클라이언트가 DBMS에 SQL을 발행해서 데이터를 저장하지만, 쿠키의 경우는 거꾸로 서버가 클라이언트에 '이 파일을 보관해줘'라고 쿠키 저장을 지시한다.
쿠키도 HTTP 헤더를 기반으로 구현됐다. 서버에서는 다음과 같이 응답 헤더를 보낸다. 이 서버는 최종 액세스 날짜와 시간을 클라이언트에 저장하려고 한다.
```
Set-Cookie: LAST_ACCESS_DATE=Jul/31/2016
Set-Cookie: LAST_ACCESS_TIME=12:0
```
클라이언트는 이 값을 저장해둔다. 다음번에 방문할 때는 다음과 같은 형식으로 보낸다. 서버는 이 값을 읽고, 클라이언트가 마지막으로 엑세스한 시간을 알 수 있다.
```
Cookie: LAST_ACCESS_DATE=Jul/31/2016
Cookie: LAST_ACCESS_TIME=12:10
```
해당 쿠키 값으로 표시 내용을 바꾸는 코드를 작성할 수 있다.
```go
func handlerCookie(w http.ResponseWriter, r *http.Request) {
	w.Header().Add("Set-Cookie", "VISIT=TRUE")
	if _, ok := r.Header["Cookie"]; ok {
		fmt.Fprintf(w, "<html><body>2번째 이후</body></html>\n")
	} else {
		fmt.Fprintf(w, "<html><body>첫 방문</body></html>\n")
	}
	dump, err := httputil.DumpRequest(r, true)
	if err != nil {
		http.Error(w, fmt.Sprint(err), http.StatusInternalServerError)
		return
	}
	fmt.Println(string(dump))
}
```
서버 프로그램이 볼 땐 마치 데이터베이스처럼 외부에 데이터를 저장해두고, 클라이언트가 액세스할 때마다 데이터를 로드하는 것과 같다. HTTP는 스테이트리스를 기본으로 개발됐지만, 쿠키를 이용하면 서버가 상태를 유지하는 스테이트풀처럼 보이게 서비스를 제공할 수 있다.
브라우저에서도 자바스크립트로 쿠키를 읽어내거나 서버에 보낼 때 쿠키를 설정할 수 있다. 
curl 커맨드를 사용할 때도 헤더로서 받은 내용을 `Cookie`에 넣고 재전송함으로써 실현할 수 있지만, 쿠키를 위한 전용 옵션도 있다. `-c/--cookie-jar` 옵션으로 지정한 파일에 수신한 쿠키를 저장하고, `-b/--cookie` 옵션으로 지정한 파일에서 쿠키를 읽어와 전송한다. 브라우저처럼 동시에 송수신하려면 둘 다 지정한다.
## 5.1 쿠키의 잘못된 사용법
### 영속성 문제
쿠키는 어떤 상황에서도 확실하게 저장되는 것은 아니다. 서버가 쿠키를 데이터 베이스 대신으로 쓸 수는 없다. 쿠키가 초기화되면 저장된 데이터는 사라진다. 따라서 사라지더라도 문제가 없는 정보나 서버 정보로 복원할 수 있는 자료를 저장하는 용도에 적합하다.
### 용량 문제
쿠키의 최대 크기는 4킬로바이트 사양으로 정해져있다. 쿠키는 헤더로 항상 통신에 부가되므로 통신량이 늘어나는 문제가 있다. 제한된 용량과 통신량 증가는 DB로 사용하는 데 제약이 된다.
### 보안 문제
HTTP 통신에서는 쿠키가 평문으로 전송된다. 암호화된다고 해도 사용자가 자유롭게 접근할 수 있는 것도 문제이다. 원리상 사용자가 쿠키를 수정할 수도 있으므로 수정되면 오작동으로 이어지는 민감한 정보를 넣는 데도 적합하지 않다. 정보를 넣을 때는 서명이나 암호화 처리가 필요하다.
## 5.2 쿠키에 제약을 주다
쿠키는 특정 서비스를 이용하는 토큰으로 이용될 때가 많아 쿠키가 필요하지 않은 서버에 전송하는 것은 보안이 위험해질 분이다. 그러므로 쿠키를 제한하는 속성이 몇 가지 정의되어 있다. HTTP 클라이언트는 이 속성을 해석해 쿠키 전송을 제어할 책임이 있다.
속성은 세미콜론으로 구분해 얼마든지 나열할 수 있다. 속성은 대문자와 소문자를 구별하지 않는다.
```
Set-Cookie: SID=31d4d96e407aaad42; Path=/; Secure; HttpOnly
Set-Cookie: lang=en-US; Path=/; Domain=example.com
```
- `Expires, Max-Age`: 쿠키의 수명을 설정 `Max-Age`는 현재 시각에서 지정된 초수를 더한 시간에서 무효가 된다. `Expires`는 `Wed, 09 Jul 2021 10:18:14 GMT`같은 형식의 문자열을 해석한다.
- `Domain`: 클라이언트에서 쿠키를 전송할 대상 서버, 생략하면 쿠키를 발행한 서버가 된다.
- `Path`: 클라이언트에서 쿠키를 전송할 대상 서버의 경로, 생략하면 쿠키를 발행한 서버의 경로다.
- `Secure`: https로 프로토콜을 사용한 보안 접속일 때만 클라이언트에서 서버로 쿠키를 전송한다. 
- `HttpOnly`: 자바스크립트 엔진으로부터 쿠키를 감출 수 있다. 크로스 사이트 스크립팅등 악의적인 자바스크립트가 실행되는 보안 위험에 대한 방어가 된다.
- `SameSite`: 같은 오리진(출처)의 도메인에 전송하게 된다.
# 6 인증과 세션
인증에는 몇 가지 방식이 있다. 유저명과 패스워드를 매번 클라이언트에서 보내는 방식 두 가지를 먼저 소개한다.
## BASIC 인증과 Digest 인증
BASIC 인증은 유저명과 패스워드를 BASE64로 인코딩한 것이다. 이는 가역변환이므로 서버로부터 복원해 원래 유저명과 패스워드를 추출할 수 있다. SSL/TLS 통신을 사용하지 않은 상태에서 통신이 감청되면 손쉽게 로그인 정보가 유출된다.
```
base64(유저명+":"+패스워드)
```
curl 커맨드로 BASIC 인증을 할 경우, `-u/--user` 옵션으로 유저명과 패스워드를 보낸다. `--basic` 이라고 명시할 수도 있으나 기본 인증 방식이 BASIC이다.
```shell
$ curl --http1.0 --basic -u user:pass http://localhost.8080
```
다음과 같은 헤더가 부여된다.
```
Authorization: "Basic dXNlcjpwYXNz"
```
이보다 더 강력한 방식이 Digest 인증이다. 이는 해시 함수를 이용한다. 브라우저가 보호된 영역에 접속하려고 하면, `401 Unauthorized`라는 스테이터스 코드로 응답이 돌아온다. 이때 아래와 같은 헤더가 부여된다.
```
WWW-Aunthenticate: Digest realm="영역명", nonce="1234567890", algorithm=MD5, qop="auth"
```
`realm`은 보호되는 영역의 이름으로, 인증창에 표시된다. `nonce`는 서버가 매번 생성하는 랜덤한 데이터이다. `qop`는 보호 수준을 나타낸다. 클라이언트는 이곳에서 주어진 값과 무작위로 생성한  `cnonce`를 바탕으로 다음처럼 계산해서  `response`를 구현한다.
```
A1 = 유저명":"realm":"패스워드"
A2 = HTTP 메서드 ":" 콘텐츠 URI
response = MD5( MD5(A1)":"nonce":"nc":"cnonce":"qop":"MD5(A2))
```
`nc`는 특정 `nonce`값을 사용해 전송한 횟수이다. `qop`가 없을 때는 생략한다. 8자리 16진수로 표현한다. 같은 `nc`값이 다시 사용된 것을 알 수 있으므로, 서버가 리플레이 공격을 탐지할 수 있다.
클라이언트에서는 생성한 `cnonce`와 계산으로 구한 `response`를 부여해 한데 모으고, 다음과 같은 헤더를 덧붙여 재요청을 보낸다.
```
Authorization: Digest username="유저명", realm="유저명",
	nonce="1234567890", uri="/secret.html", algorithm=MD5,
	qop=auth, nc=00000001, cnonce="0987654321",
	response="9d47a3f8b2d5c"
```
서버 측에서도 이 헤더에 있는 정보와 서버에 저장된 유저명, 패스워드로 같은 계산을 실시한다. 재발송된 요청과 동일한 `response`가 계산되면 사용자가 정확하게 유저명과 패스워드를 입력했음을 보증할 수 있다. 이로써 유저명과 패스워드 자체를 요청에 포함하지 않고도 서버에서 사용자를 올바르게 인증할 수 있게 된다.
curl에서는 `--digest`와 `-u/--user` 옵션으로 Digest 인증을 사용할 수 있지만, 테스트 서버는 `401`을 반환하지 않으므로 지금 상태로는 접속이 그대로 종료된다.  `/digest`라는 패스에서 `Authorization` 헤더가 없을 때 `401`을 반환하도록 테스트 서버에 핸들러 함수를 추가한다.
```go
package main

import (
	"fmt"
	"io"
	"log"
	"net/http"
	"net/http/httputil"

	"github.com/k0kubun/pp"
)

func handlerDigest(w http.ResponseWriter, r *http.Request) {
	pp.Printf("URL: %s\n", r.URL.String())
	pp.Printf("Query: %s\n", r.URL.Query())
	pp.Printf("Proto: %s\n", r.Proto)
	pp.Printf("Method: %s\n", r.Method)
	pp.Printf("Header: %v\n", r.Header)
	defer r.Body.Close()
	body, _ := io.ReadAll(r.Body)
	fmt.Printf("--body--\n%s\n", string(body))
	if _, ok := r.Header["Authorization"]; !ok {
		w.Header().Add("WWW-Authenticate", `Digest realm="Secret Zone", nonce="TgLc25U2BQA=f510a2780473e18e6587be702c2e67fe2b04afd", algorithm=MD5, qop="auth"`)
		w.WriteHeader(http.StatusUnauthorized)
	} else {
		fmt.Fprintf(w, "<html><body>secret page</body></html>\n")
	}
}

func handler(w http.ResponseWriter, r *http.Request) {
	dump, err := httputil.DumpRequest(r, true)
	if err != nil {
		http.Error(w, fmt.Sprint(err), http.StatusInternalServerError)
		return
	}
	fmt.Println(string(dump))
	fmt.Fprintf(w, "<html><body>hello</body></html>\n")
}

func main() {
	var httpServer http.Server
	http.HandleFunc("/", handler)
	http.HandleFunc("/digest", handlerDigest)
	log.Println("start http listening :8080")
	httpServer.Addr = ":8080"
	log.Println(httpServer.ListenAndServe())
}

```

```shell
$ curl -v --http1.0 --digest -u user:pass http://localhost:8080/digest
*   Trying 127.0.0.1:8080...
* Connected to localhost (127.0.0.1) port 8080 (#0)
* Server auth using Digest with user 'user'
> GET /digest HTTP/1.0
> Host: localhost:8080
> User-Agent: curl/7.88.1
> Accept: */*
> 
* HTTP 1.0, assume close after body
< HTTP/1.0 401 Unauthorized
< Www-Authenticate: Digest realm="Secret Zone", nonce="TgLc25U2BQA=f510a2780473e18e6587be702c2e67fe2b04afd", algorithm=MD5, qop="auth"
< Date: Mon, 28 Apr 2025 17:47:34 GMT
< Content-Length: 0
< 
* Closing connection 0
* Issue another request to this URL: 'http://localhost:8080/digest'
* Hostname localhost was found in DNS cache
*   Trying 127.0.0.1:8080...
* Connected to localhost (127.0.0.1) port 8080 (#1)
* Server auth using Digest with user 'user'
> GET /digest HTTP/1.0
> Host: localhost:8080
> Authorization: Digest username="user", realm="Secret Zone", nonce="TgLc25U2BQA=f510a2780473e18e6587be702c2e67fe2b04afd", uri="/digest", cnonce="OTNiZTc3NzBiMTk3M2MyZGVkNDY1YTkzMzA2NDk2NDY=", nc=00000001, qop=auth, response="48abb8b147b3e265c0fcb970f227b18d", algorithm=MD5
> User-Agent: curl/7.88.1
> Accept: */*
> 
* HTTP 1.0, assume close after body
< HTTP/1.0 200 OK
< Date: Mon, 28 Apr 2025 17:47:34 GMT
< Content-Length: 38
< Content-Type: text/html; charset=utf-8
< 
<html><body>secret page</body></html>
* Closing connection 1
```

## 6.2 쿠키를 사용한 세션 관리
지금은 다음의 이유들 때문에 위 두 인증은 잘 사용되지 않는다.
- 톱페이지 접속과 동시에 로그인 창을 표시해야 한다. 처음 방문하는 사용자에게 친절한 톱페이지는 아니다.
- 요청할 때마다 유저명과 패스워드를 보내고 계산해서 인증할 필요가 있다.
- 로그인 화면을 사용자화할 수 없다. 
- 명시적으로 로그오프를 할 수 없다.
- 로그인한 단말을 식별할 수 없다.
폼을 이용한 로그인과 쿠키를 이용한 세션 관리 조합을 많이 사용한다. 이 방식으로는 폼과 쿠키를 이용하는 단순한 구조가 된다.
클라이언트는 폼으로 ID와 비밀번호를 전송한다. ID와 패스워드를 직접 송신하므로 SSL/TLS가 필수이다. 서버 측에서는 인증에 문제가 없으면 세션 토큰을 발행한다. 서버는 세션 토큰을 DB에 저장해둔다. 토큰은 쿠키로 클라이언트에게 되돌아간다. 두 번째 이후 접속에서는 쿠키를 재전송해서 로그인된 클라이언트임을 서버가 알 수 있다.
## 6.3 서명된 쿠키를 이용한 세션 데이터 저장
웹 애플리케이션 프레임워크는 영속화 데이터를 읽고 쓰는 OR 매퍼 등의 시스템과 함께 휘발성 높은 데이터를 다루는 세션 스토리지 기능을 갖추고 있다. 예전 세션 스토리지는 RDB에 전용 테이블을 만들고 세션 관리에서 작성한 ID를 키로 삼아 서버측에서 데이터를 관리했다.
통신 속도가 빨라지고 웹사이트 자체의 데이터양도 늘어나면서 쿠키의 데이터 양 증가는 걱정할 필요가 없어졌다. 그래서 쿠키를 사용한 데이터 관리 시스템도 널리 사용되기 시작했다.
최근 세션 스토리지는 쿠키를 이용해 데이터를 저장한다. 변조되지 않도록 클라이언트에 전자 서명된 데이터를 보낸다.
이 시스템의 장점은 서버 측에서 데이터저장 시스템을 준비할 필요가 없다는 점이다. 마이크로서비스라도 세션 스토리지 암호화 방식을 공통화해두면 따로 데이터스토어를 세우지 않고 세션 데이터를 읽고 쓸 수 있게 된다.
클라이언트 입장에서 보면 서버에 엑세스 해서 조작한 결과가 쿠키로 저장된다. 쿠키를 갖고 있는 한 임시 데이터가 유지된다.
# 7 프록시
프록시는 HTTP 등의 통신을 중계한다. 캐시 기능이 있는 프록시를 조직의 네트워크 출입구에 설치하면 콘텐츠를 저장한 웹 서버의 부담은 줄이고 각 사용자가 페이지를 빠르게 열람할 수 있게 한다. 외부 공격으로부터 네트워크를 보호하는 방화벽 역할도 한다. 저속 통신 회선용으로 데이터를 압축해 속도를 높이는 필터나 콘텐츠 필터링 등에도 프록시가 이용된다.
프록시 구조는 단순해서 `GET`등의 메서드 다음에 오는 경로명 형식만 바뀐다. 메서드 뒤의 경로명은 보통 `/helloworld` 처럼 슬래시로 시작되는 유닉스 형식의 경로명이 되지만, 프록시를 설정하면 스키마도 추가돼, `http://`나 `https://`로 시작되는 URL 형식이 된다. HTTP/1.1부터 등장한 `Host`헤더도 최종적으로 요청을 받는 서버명 그대로이다. 실제로 요청을 보내는 곳은 프록시 서버가 된다.
이번 테스트 서버는 프록시용 통신도 그 자리에서 응답해버리지만, 원래는 중계할 곳으로 요청을 리디렉트하고 결과를 클라이언트에 반환한다.
프록시 서버가 악용되지 않도록 인증을 이용해 보호하는 경우가 있다. 이런 경우는 `Proxy-Authenticate` 헤더에 인증 방식에 맞는 값이 들어간다. 중계되는 프록시는 중간의 호스트 IP 주소를 특정 헤더에 기록해 간다. 예전부터 사용한 것은 `X-Forwarded-For`헤더이다. 
프록시를 설정하려면 `-x/--proxy` 옵션을 사용한다. 프록시 인증용 유저명과 패스워드는 `-U/--proxy-user` 옵션을 이용한다.
```
$curl --http1.0 -x http://localhost:8080 -U user:pass http://example.com/helloworld
```
프록시와 비슷한 것으로는 게이트웨이가 있다. HTTP/1.0에서는 다음과 같이 정의되어 있다.
- 프록시: 통신의 내용을 이해한다. 필요에 따라서 콘텐츠를 수정하거나 서버 대신 응답한다.
- 게이트웨이: 통신 내용을 그대로 전송한다. 내용의 수정도 불허한다. 클라이언트에서는 중간에 존재하는 것을 알아채서는 안된다.
HTTPS 통신의 프록시 지원은 HTTP/1.0에서 추가된 `CONNECT` 메서드를 이용한다.

# 8 캐시
웹사이트의 콘텐츠가 풍부해지며 한 페이지를 표시하는 데도 수십 개의 파일이 필요해졌다. 모든 파일을 접속할 때마다 다시 다운로드해야 한다면 전부 표시하기 까지 시간이 꽤 걸린다. 그래서 콘텐츠가 변경되지 않았을 땐 로컬에 저장된 파일을 재사용함으로써 다운로드 횟수를 줄이고 성능을 높이는 '캐시' 메커니즘이 등장했다.
지금은 캐시 관련 규악이 복잡해졌지만, 최초 버전은 단순했다. `GET`과 `HEAD`메서드 이외에는 기본적으로 캐시되지 않는다.
## 8.1 갱신 일자에 따른 캐시
우선 HTTP/1.0에서의 캐시를 설명한다. 당시는 정적 콘텐츠 위주라서 콘텐츠가 갱싱됐는지만 비교하면 충분했다. 웹서버는 대개 다음과 같은 헤더를 응답에 표함한다.
```
Last-Modified: Wed, 08 Jun 2015 15:23:45 GMT
```
웹 브라우저가 캐시된 URL을 다시 읽을 때는 서버에서 반환된 일시를 그대로 `IF-Modified-Since` 헤더에 넣어 요청한다.
```
IF-Modified-Since: Wed, 08 Jun 2015 15:23:45 GMT
```
웹 서버는 요청에 포함된 `IF-Modified-Since`의 일시와 서버의 콘텐츠의 일시를 비교한다. 변경됐으면 정산 스테이터스 코드 `200 OK`를 반환하고 콘텐츠를 응답 바디에 실어버 보낸다. 변경되지 않았으면, 스테이터스 코드 `304 Not Modified`를 반환하고 바디를 응답에 포함하지 않는다.
## 8.2 Expires
갱신 일시를 이용하는 캐시의 경우 캐시의 유효성을 확인하기 위해 통신이 발생한다. HTTP/1.0에서는 `Expires` 헤더를 이용해 이 통신 자체를 없앴다.
`Expires` 헤더에는 날짜와 시간이 들어간다. 클라이언트는 지정한 기간 내라면 캐시가 '신선'하다고 판단해 강제로 캐시를 이용한다. 다시 말해 요청을 아예 전송하지 않는 것이다. 캐시의 유효 기간이 지났으면 캐시가 신선하지 않다(stale)고 판단한다.
여기서 설정된 날짜와 시간은 어디까지나 접속을 할지 말지 판단할 때만 사용한다. 해당 시간이 지났다고 마음대로 리로드하지는 않는다.
`Expires`를 사용하면 서버에 변경 사항이 있는지 묻지 않게 되므로 스타일시트 등 좀 처럼 갱신되지 않는 정적 콘텐츠에 사용하는 것이 바람직하다.
## 8.3 Pragma: no-cache
클라이언트가 프록시 서버에 `Pragam` 헤더를 통해 지시할 수도 있다. `Pragma` 헤더에 포함할 수 있는 페이로드로 유일하게 HTTP 사양으로 정의된 것이 `no-cache`이다.
`no-cache`는 요청한 콘텐츠가 이미 저장돼 있어도, 원래 서버에서 가져오라고 프록시 서버에 지시하는 것이다. HTTP/1.1에 이르러 `Cache-Control`로 통합됐지만, 1.1 이후에도 하위 호환성 유지를 위해 남아있다.
몇 가지 캐시 메커니즘이 있지만, 그다지 적극적으로 사용되진 않는다. HTTP는 스테이트리스한 프로토콜로 셜계됐고, REST는 클라이언트가 콘텐츠의 의미등을 사전 지식으로 갖지 않는 것을 목표로 한다. 클라이언트가 정보의 수명과 품질을 일일이 관리하는 상태는 부자연스럽다.
게다가 프록시가 어느 정도 지시를 이해하고 기대한 대로 동작할지 보증할 수도 없다. 중간에서 프록시가 하나라도 `no-cache`를 무시하면 기대한 대로 동작하지 않는다.
HTTP/2가 등장한 이후로는 보안 접속 비율이 증가했다. 보안 통신에서는 프록시가 통신 내용을 감시할 수 없고 중계만 할 수 있다. 프록시의 캐시를 외부에서 적극적으로 관리하는 의미가 이제는 없다고도 말할 수 있다.
## 8.4 ETag 추가
동적으로 바뀌는 요소가 늘어날수록(이미 구매한 상품, 프리미엄 회원 등) 어떤 날짜를 근거로 캐시의 유효성을 판단해야 하는지  판단하기 어려워진다.
이때 사용할 수 있는 것이 HTTP/1.1에서 추가된 ETag이다. ETag는 순차적인 갱신 일시가 아니라 파일의 해시 값으로 비교한다. 서버는 응답에 `ETag` 헤더를 부여한다. 두 번째 이후 다운로드 시 클라이언트는 `IF-None-Match` 헤더에 다운로드된 캐시에 들어있던 `ETag` 값을 추가해 요청한다. 서버는 보내려는 파일의 `ETag`와 비교해서 같으면 `304 Not Modified`로 응답한다. 여기까지는 HTTP/1.0에도 있었던 캐시 제어 구조이다.
`ETag`는 서버가 자유롭게 결정해서 반환할 수 있다.
## 8.5 Cache-Control
`ETag`와 같은 시기에 HTTP/1.1에 추가됐다. 서버는 더 유연한 캐시 제어를 지시할 수 있다. `Expires`보다 우선해서 처리된다. 먼저 서버가 응답으로 보내는 헤더로 아래와 같은 키를 사용할 수 있다.
- `public`: 같은 컴퓨터를 사용하는 복수의 사용자 간 캐시 재사용을 허가한다.
- `private`: 같은 컴퓨터를 사용하는 다른 사용자 간 캐시를 재사용하지 않는다.
- `max-age=n`: 캐시의 신선도를 초단위로 설정. 캐시가 유효하면 서버에 문의하지 않고 캐시를 이용한다. 그 이후는 서버에 문의한 뒤 `304 Not Modified`가 반환됐을 때만 캐시를 이용한다.
- `s-maxage=n`: `max-age`와 같으나 공유 캐시에 대한 설정값이다.
- `no-cache`: 캐시가 유효한지 매번 문의한다.
- `no-store`: 캐시하지 않는다.
`no-cache`는 시간을 보고 서버에 접속하지 않은 채 콘텐츠를 재이용하는 것을 그만둘 뿐이다. 갱신 일자와 `ETag`를 사용하며, 서버가 `304`를 반환했을 때 이용하는 캐시는 유효하다. 캐시하지 않는 것은 `no-store`이다.
서버에 접속 부분에서는 앞에서 설명한 날짜와 `ETag`를 이용한 캐시 로직이 들어간다.

`Cache-Control` 헤더를 요청 헤더에 포함함으로써 프록시에 지시할 수 있다. 서버에서 프록시로 보내는 응답 헤더에 사용할 수 있는 지시도 있다.
## 8.7 Vary
같은 URL이라도 클라이언트에 따라 반환 결과가 다름을 나타내는 헤더가 `Vary`이다. 예를 들어, 사용자의 브라우저가 스마트폰용 브라우저일 때는 모바일용 페이지가 표시되고, 사용하는 언어에 따라 내용이 바뀌는 경우를 들 수 있다. 이처럼 표시가 바뀌는 이유에 해당하는 헤더명을 `Vary`에 나열함으로써 잘못된 콘텐츠의 캐시로 사용되지 않게 한다.
```
Vary: User-Agent, Accept-Language
```
# 리퍼러
사용자가 어느 경로로 웹사이트에 도달했는지 서버가 파악할 수 있도록 클라이언트가 서버에 보내는 헤더이다. 웹페이지가 이미지나 스크립트를 가져올 경우는 리소스를 요청할 때 리소스를 이용하는 HTML 파일의 URL이 리퍼러로서 전송된다.
검색 엔진은 검색 결과를 `'?q=키워드'` 의 형식의 URL로 표시한다. 브라우저가 이 URL을 리퍼러로서 전송하면, 서버는 어떤 검색 키워드로 웹사이트에 도달했는지 알 수 있다. 웹 서비스는 리퍼러 정보를 수집함으로써 어떤 페이지가 자신의 서비스에 링크를 걸었는지도 알 수 있다.
`GET` 파라미터는 리퍼러를 통해 외부 서비스로 전송되므로 바로 개인 정보 유출로 이어지기 때문에 개인 정보가 `GET` 파라미터로 표시되게 만들어선 안 된다.
보호된 통신 내용이 보호되지 않은 통신 경로로 유출되는 것을 막고자 클라이언트가 리퍼러 전송을 제한하는 규약이 RFC 2616으로 제정됐다. 액세스 출발지 및 액세스 목적지의 스키마 조합과 리퍼러 전송 유무 관계는 다음 표와 같다.

| 액세스 출발지 | 액세스 목적지 | 전송하는가?  |
| ------- | ------- | ------- |
| HTTPS   | HTTPS   | 한다.     |
| HTTPS   | HTTP    | 하지 않는다. |
| HTTP    | HTTPS   | 한다.     |
| HTTP    | HTTP    | 한다.     |
리퍼러 정책으로서 설정할 수 있는 값에는 다음과 같은 것들이 있다.
- `no-referrer`: 전혀 보내지 않는다.
- `no-referrer-when-downgrade`
- `same-origin`: 동일 도메인 내의 링크에 대해서만 리퍼러를 전송한다.
- `strict-origin`
- `origin-when-crossorigin`: 같은 도메인 내에서는 완전 리퍼러를, 다른 도메인에는 도메인 이름만 전송한다.
- `strict-origin-when-crossorigin`
- `unsafe-url`: 항상 전송한다.
이 밖에도 `Content-Security-Policy` 헤더로 지정할 수도 있다.
# 10 검색 엔진용 콘텐츠 접근 제어
인터넷은 브라우저를 이용해 문서를 열람하는 구조로 출발했지만, 검색 엔진이 정보를 수집하는 자동 순회 프로그램이 많이 운용되게 됐다. 
크롤러의 접근을 제어하는 방법으로 주로 다음 두 가지가 널리 사용된다.
- robots.txt
- 사이트맵
## 10.1 robots.txt
서버 콘텐츠 제공자가 크롤러에게 접근 허가 여부를 전하기 위한 프로토콜이다. 규칙을 기술한 파일명이다. 이 규칙을 읽고 해석해 실제로 접근을 중단하는 것은 크롤러 쪽이다.
robots.txt는 다음과 같은 형식으로 읽기를 금지할 크롤러의 이름과 장소를 지정한다.
```
User-agent= *
Disallow: /cgi-bin/
Disallow: /tmp/
```
이와 비슷한 내용을 HTML의 메타 태그로도 기술할 수 있다. robots.txt.가 우선하지만, 메타 태그로 더 자세히 지정할 수 있다.
```
<meta name="robots" content="noindex"/>
```
`content` 속성에는 다양한 디렉티브를 기술할 수 있다.
## 10.2 사이트맵
웹사이트에 포함된 페이지 목록과 메타데이터를 제공하는 XML 파일이다. robots.txt가 블랙리스트 처럼 사용된다면 사이트맵은 화이트리스트 처럼 사용된다. 크롤러는 링크를 따라가면서 페이지를 찾아낸다. 동적 페이지의 링크처럼 크롤러가 페이지를 찾을 수 없는 경우라도 사이트맵으로 보완할 수 있다.
xml 형식으로 기술한다.
```xml
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://example.com/</loc>
    <lastmod>2024-04-28</lastmod>
    <changefreq>weekly</changefreq>
    <priority>1.0</priority>
  </url>
  <url>
    <loc>https://example.com/about</loc>
    <lastmod>2024-04-20</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
</urlset>
```
`<url>` 태그를 등록하고 싶은 페이지 수만큼 작성한다. `<loc>`는 절대 URL이다. XML이 가장 많이 사용되지만 단순히 URL이 나열된 텍스트 파일이나 RSS,아톰 같은 블로그의 업데이트 정보 통지에 쓰이는 형식도 사이트맵으로 사용할 수 있다.
사이트맵은 robots.txt에 쓸 수도 있다.
# 11 요약
브라우저가 사용자가 경험을 개선하기 위해 HTTP의 기본 [[1. HTTP1.0의 신택스 기본이 되는 네가지 요소|네 가지 요소]]를 어떻게 사용하는지 살펴봤다.
- 폼과 파일 전송
- 콘텐트 니고시에이션
- 캐시와 콘텐츠 압축에 따른 전송량 절감과 응답 개선
- 브라우저가 기대하는 언어의 콘텐츠와 기대하는 이미지 포맷의 파일을 취득
- 인증을 거쳐 사용자 고유의 콘텐츠를 표시하는 시스템
- 쿠키를 사용해 액세스할 때마다 로그인 조작을 하지 않아도 되는 시스템
- 프록시를 사용한 외부 캐시와 필터링 도입
- 리퍼러
- 검색 엔진용 엑세스 제한
HTTP는 효율적으로 계층화되어 있다. 통신의 데이터 상자 부분은 변하지 않으므로, 규격에서 제안된 새로운 기능이 구현되지 않아도 호환성을 유지하기 쉽도록 되어 있따. 토대가 되는 문법(신택스)과 그 문법을 바탕으로 한 헤더의 의미해석(시맨틱스)이 분리되어 있으므로 상위 호환성과 하위 호환성이 모두 유지된다.

#CS #Network 
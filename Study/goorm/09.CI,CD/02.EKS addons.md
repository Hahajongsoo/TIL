| k8s                 | aws                 |
| ------------------- | ------------------- |
| lb service, ingress | aws lb controller   |
| volume              | EBS CSI provisioner |
| metrics-server, hpa |                     |
| logging, monitoring | cloud watch         |
| serverless          | fargate             |
| rbac                | IAM                 | 
다른 애드온들을 사용한다는 것은 쿠버네티스는 물론 aws의 다른 리소스들도 사용한다는 것이다. 그렇기 때문에 해당 EC2 인스턴스(워커 노드)가 그에 맞는 권한을 가지고 있어야 한다. 이런 정책들을 eksctl config에 지정하게 되고 생성된 ec2 인스턴스의 보안 탭에서 iam과 정책을 확인할 수 있다.

# AWS Load Balancer Controller
애드온 없이 로드밸런서를 생성하면 aws의 clb가 생성된다. clb는 기능상 제약이 있기 때문에 이 보다는 NLB와 ALB를 만드는 것이 필요하고 이를 위해서 AWS Load Balancer Controller가 필요하다.
[aws 공식 문서](https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html) [AWS LB Controller 공식문서](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/)
LB와 관련된 역할은 다음 파일에 적혀있다. [링크](https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.7/docs/install/iam_policy.json) 우리는 클러스터 생성시 이미 SA와 역할을 지정했기 때문에 할 필요는 없지만 원래 어떻게 진행되는지 확인할 필요가 있다.
1. LB 관련 정책에 대한 문서를 다운로드 받는다.
2. aws cli 로 다운로드 받은 문서를 기반으로 iam을 만든다.
3. ekscli로 클러스터에 관련 sa를 만들고 해당 sa와 역할을 바인딩하기위해서 iam 정책을 인자로 추가한다. 이러면 rbac 대신 iam이 바인딩되어 aws 리소스를 제어할 수 있게 된다.

헬름을 이용해서 애드온을 설치를 한다. sa를 이미 만들었기 때문에 sa를 만들 필요는 없다. 
```
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=my-cluster \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller 
```

## NLB
어노테이션에 따라서 LB가 만들어지는 방식이 달라진다. NLB를 생성하기 위해서 추가해야 하는 어노테이션이 있고 
```
service.beta.kubernetes.io/aws-load-balancer-type: "external"
service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
```
LB를 외부에 만들기 위해서 추가해야 하는 어노테이션이 있다.
```
service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
```

위의 경우 IP targets로 NLB가 만들어진다. Instance targets로 하려면 또 다른 어노테이션을 사용해야 한다. 
[링크](https://docs.aws.amazon.com/eks/latest/userguide/network-load-balancing.html)

## ALB
인그레스를 만들때에는 ALB를 만들어야하고 마찬가지로 어노테이션을 지정해줘야 한다. [링크](https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html) NLB를 만들 때와 마찬가지로 어떤 타입인지, 타겟이 어딘지, internet-facing인지 아닌지 등을 어노테이션으로 지정하여 리소스를 생성한다.

# Volume
SC가 있더라도 관련 프로비저너가 없기 때문에 볼륨을 생성할 수 없다. 따라서 EBS CSI provisioner를 설치해줘야 한다.
로드밸런서때와 마찬가지로 SA와 IAM을 만들어줘야하지만 우리는 이미 클러스터를 생성할 때 생성했다.[링크](https://docs.aws.amazon.com/eks/latest/userguide/csi-iam-role.html)

이후에는 ekscli를 이용하여 애드온을 생성한다. [링크](https://docs.aws.amazon.com/eks/latest/userguide/managing-ebs-csi.html) 이때 클러스터 이름과 iam의 arn값을 바꿔줘야 한다. arn은 서비스계정의 어노테이션에서 확인할 수 있다.
```
kubectl -n kube-system describe sa ebs-csi-controller-sa
Name:                ebs-csi-controller-sa
Namespace:           kube-system
Labels:              app.kubernetes.io/managed-by=eksctl
Annotations:         eks.amazonaws.com/role-arn: arn:aws:iam::686820597897:role/eksctl-myeks-addon-iamserviceaccount-kube-sy-Role1-UG4MC90U3JIM
Image pull secrets:  <none>
Mountable secrets:   <none>
Tokens:              <none>
Events:              <none>
```

```
$eksctl create addon --name aws-ebs-csi-driver --cluster myeks --service-account-role-arn arn:aws:iam::686820597897:role/eksctl-myeks-addon-iamserviceaccount-kube-sy-Role1-UG4MC90U3JIM --f
orce
2023-02-28 11:29:39 [ℹ]  Kubernetes version "1.24" in use by cluster "myeks"
2023-02-28 11:29:39 [ℹ]  using provided ServiceAccountRoleARN "arn:aws:iam::686820597897:role/eksctl-myeks-addon-iamserviceaccount-kube-sy-Role1-UG4MC90U3JIM"
2023-02-28 11:29:39 [ℹ]  creating addon


$eksctl get addon --cluster myeks
2023-02-28 11:30:00 [ℹ]  Kubernetes version "1.24" in use by cluster "myeks"
2023-02-28 11:30:00 [ℹ]  getting all addons
2023-02-28 11:30:01 [ℹ]  to see issues for an addon run `eksctl get addon --name <addon-name> --cluster <cluster-name>`
NAME                    VERSION                 STATUS          ISSUES  IAMROLE               UPDATE AVAILABLE CONFIGURATION VALUES
aws-ebs-csi-driver      v1.16.0-eksbuild.1      CREATING        0       arn:aws:iam::686820597897:role/eksctl-myeks-addon-iamserviceaccount-kube-sy-Role1-UG4MC90U3JIM
```

관련 파드들이 생성되어 있는 것을 확인할 수 있다.
```
kubectl get pods -n kube-system                         
NAME                                            READY   STATUS    RESTARTS   AGE
aws-load-balancer-controller-54f797666b-wg628   1/1     Running   0          38m
aws-load-balancer-controller-54f797666b-zxrfd   1/1     Running   0          38m
aws-node-45r9w                                  1/1     Running   0          45m
aws-node-zj2m6                                  1/1     Running   0          45m
coredns-dc4979556-7z4pz                         1/1     Running   0          58m
coredns-dc4979556-vm5qr                         1/1     Running   0          58m
ebs-csi-controller-c687d8b75-llqmh              6/6     Running   0          70s
ebs-csi-controller-c687d8b75-x2zvk              6/6     Running   0          70s
ebs-csi-node-vhc76                              3/3     Running   0          70s
ebs-csi-node-x88rn                              3/3     Running   0          70s
kube-proxy-rtp5t                                1/1     Running   0          45m
kube-proxy-wnt64                                1/1     Running   0          45m
```

AWS ebs의 경우 블록스토리지로 ReadWriteOnce만 지원한다.
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myapp-pvc-dynamic
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: gp2
```

## storageclass
[링크](https://kubernetes.io/docs/concepts/storage/storage-classes/#aws-ebs) [링크](https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/storage-classes.html)
AWS EBS 스토리지 클래스에 대해서 다른 타입의 볼륨과 파일시스템을 지정할 수 있다. 다른 파라미터로 다른 스토리지 클래스를 생성하면 되는 것이다.
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3
  #annotations:
  #  storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
parameters:
  csi.storage.k8s.io/fstype: ext4
  type: gp3
```
volumeBindingMode에 따라서 PV가 생성되는 방식이 다르다. Immediate의 경우 PV는 바로 생성된다. WatiForFirstConsumer의 경우 파드가 PVC를 요청하기 전 까지는 PV가 생성되지 않는다. 리소스마다 요금이 부과되는 aws 등의 클라우드 환경에서는 WatiForFirstConsumer를 사용하는 것이 합리적이라고 볼 수 있다.

# metrics server
[설치 링크](https://github.com/kubernetes-sigs/metrics-server#installation) 설치는 간단하다.
```shell
$ kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
```

설치 이후 top 서브커맨드나 hpa 리소스가 사용가능한 것을 확인할 수 있다.

```
$ kubectl top nodes
NAME                                                 CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
ip-192-168-125-123.ap-northeast-2.compute.internal   40m          2%     558Mi           16%       
ip-192-168-186-169.ap-northeast-2.compute.internal   44m          2%     534Mi           16% 
```

# Cluster Autoscaling
eks config 파일에서 NodeGroup을 만들게 되면 aws autoscaling 그룹도 만들어진다. 
현재 지정된 노드 그룹을 수동으로 스케일링 하고 싶다면 `eksctl scale nodegroup` 명령으로  autoscaling 그룹을 스케일링 하면 된다.
```
$ eksctl scale nodegroup --name mynodes-t3 --cluster myeks -N 3
2023-02-28 12:28:46 [ℹ]  scaling nodegroup "mynodes-t3" in cluster myeks
2023-02-28 12:28:47 [ℹ]  waiting for scaling of nodegroup "mynodes-t3" to complete
2023-02-28 12:29:17 [ℹ]  nodegroup successfully scaled

$ kubectl get nodegroups --cluster myeks
error: no server found for cluster "myeks"

$ eksctl  get nodegroups --cluster myeks
CLUSTER NODEGROUP       STATUS  CREATED                 MIN SIZE        MAX SIZE        DESIRED CAPACITY  INSTANCE TYPE   IMAGE ID        ASG NAME                                 TYPE
myeks   mynodes-t3      ACTIVE  2023-02-28T01:44:49Z    1               3               3t3.medium        AL2_x86_64      eks-mynodes-t3-6ac34ad8-c4d0-c57e-5d35-1a100caca60c     managed

$ kubectl get nodes                     
NAME                                                 STATUS   ROLES    AGE    VERSION
ip-192-168-125-123.ap-northeast-2.compute.internal   Ready    <none>   104m   v1.24.10-eks-48e63af
ip-192-168-139-83.ap-northeast-2.compute.internal    Ready    <none>   35s    v1.24.10-eks-48e63af
ip-192-168-186-169.ap-northeast-2.compute.internal   Ready    <none>   104m   v1.24.10-eks-48e63af
```

![](images/Pasted%20image%2020230228123131.png)

## cluster autoscaler 
[링크](https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/autoscaling.html)
이전 애드온들과 마찬가지로 SA와 IAM 및 정책을 생성해야 한다. 이후 클러스터에 SA와 IAM을 바인딩 해주도록 한다. 
이후 cluster autoscaler 배포 단계에서 SA를 수정하는 단계는 생략한다. 그리고 cluster-autoscaler 버전은 github  릴리스 버전에서 내 k8s 버전중 최신 버전을 선택하여 지정한다.

```yaml
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
  - apiGroups: [""]
    resources: ["events", "endpoints"]
    verbs: ["create", "patch"]
  - apiGroups: [""]
    resources: ["pods/eviction"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["pods/status"]
    verbs: ["update"]
  - apiGroups: [""]
    resources: ["endpoints"]
    resourceNames: ["cluster-autoscaler"]
    verbs: ["get", "update"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["watch", "list", "get", "update"]
  - apiGroups: [""]
    resources:
      - "namespaces"
      - "pods"
      - "services"
      - "replicationcontrollers"
      - "persistentvolumeclaims"
      - "persistentvolumes"
    verbs: ["watch", "list", "get"]
  - apiGroups: ["extensions"]
    resources: ["replicasets", "daemonsets"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["watch", "list"]
  - apiGroups: ["apps"]
    resources: ["statefulsets", "replicasets", "daemonsets"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses", "csinodes", "csidrivers", "csistoragecapacities"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["batch", "extensions"]
    resources: ["jobs"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["create"]
  - apiGroups: ["coordination.k8s.io"]
    resourceNames: ["cluster-autoscaler"]
    resources: ["leases"]
    verbs: ["get", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create","list","watch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["cluster-autoscaler-status", "cluster-autoscaler-priority-expander"]
    verbs: ["delete", "get", "update", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '8085'
        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'
    spec:
      priorityClassName: system-cluster-critical
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      serviceAccountName: cluster-autoscaler
      containers:
        - image: registry.k8s.io/autoscaling/cluster-autoscaler:v1.24.0
          name: cluster-autoscaler
          resources:
            limits:
              cpu: 100m
              memory: 600Mi
            requests:
              cpu: 100m
              memory: 600Mi
          command:
            - ./cluster-autoscaler
            - --v=4
            - --stderrthreshold=info
            - --cloud-provider=aws
            - --skip-nodes-with-local-storage=false
            - --expander=least-waste
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/myeks
            - --balance-similar-node-groups
            - --skip-nodes-with-system-pods=false
          volumeMounts:
            - name: ssl-certs
              mountPath: /etc/ssl/certs/ca-certificates.crt #/etc/ssl/certs/ca-bundle.crt for Amazon Linux Worker Nodes
              readOnly: true
          imagePullPolicy: "Always"
      volumes:
        - name: ssl-certs
          hostPath:
            path: "/etc/ssl/certs/ca-bundle.crt"
```

# CloudWatch
![](images/Pasted%20image%2020230228143038.png)

EKS를 확인하면 어떤 로그를 남기는지 확인할 수 있다. 해당 로그는 cloudwatch에 저장이되며 해당 로그는 클러스터가 삭제되더라도 로그는 삭제되지 않고 만기가 없다.
EKS는 관리형이기 때문에 편한 부분도 있지만 컨트롤 플레인에 접근할 수 없기 때문에 컨트롤 플레인의 로그를 확인할 수 없다. 그렇기 때문에 따로 저장을 해서 확인을 하는 것이다. 
EFK 를 구성해서 로그를 검색했던 것 처럼 cloudwatch에서도 로그를 검색하고 확인할 수 있다. 
프로메테우스 대신 CloudWatch의 Container Insight를 통해 성능 모니터링을 할 수 있다. [링크](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html)

다음 쉘 명령들로 cloudwatch 와 fluent bit로 퍼포먼스 모니터링을 시작할 수 있다. 
```
ClusterName=myeks
RegionName=ap-northeast-2
FluentBitHttpPort='2020'
FluentBitReadFromHead='Off'
[[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On'
[[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On'
curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/"'${FluentBitHttpServer}'"/;s/{{http_server_port}}/"'${FluentBitHttpPort}'"/;s/{{read_from_head}}/"'${FluentBitReadFromHead}'"/;s/{{read_from_tail}}/"'${FluentBitReadFromTail}'"/' | kubectl apply -f -
```

그래도 프로메테우스가 더 좋다고 함

# Account
쿠버네티스 클러스터를 구성하고 혼자서 사용하는 경우는 드물다. 그래서 일반 계정을 만들어야 하는데 EKS로 구성한 경우 다른 사용자가 해당 EKS를 사용할 수 있도록 해야한다. EKS에서는 이것을 IAM으로 인증과 인가를 관리하는 것이다.

- 먼저 IAM에서 사용자를 추가한다. AdministratorAccess 로 구성하는 경우 모든 권한을 가지게 된다. 그리고 aws cli에서 접근할 수 있도록 액세스 키를 생성한다. 
- 생성한 액세스 키를 `~/.aws/credentials` 파일에 추가한다. 
```
$ aws configure list-profiles
default
user1
```
- AWS_PROFILE 환경 변수에 현재 사용하고 있는 계정을 지정할 수 있다.
- EKS 에는 aws-auth 라는 컨피그맵이 존재한다. 이 컨피그맵을 수정해야할 필요가 있다.
```
$ kubectl get cm -n kube-system                                           
NAME                                  DATA   AGE
aws-auth                              1      4h56m
aws-load-balancer-controller-leader   0      4h43m
cluster-autoscaler-status             1      168m
coredns                               1      5h3m
cp-vpc-resource-controller            0      5h3m
eks-certificates-controller           0      5h3m
extension-apiserver-authentication    6      5h4m
fargate-scheduler                     0      4h56m
kube-proxy                            1      5h3m
kube-proxy-config                     1      5h3m
kube-root-ca.crt                      1      5h3m
```
- 컨피그맵에 다음 내용을 추가한다 해당 내용은 생성한 IAM에 대한 내용을 추가하는 것이다. groups에는 이미 존재하는 그룹을 넣어줬는데 관련한 clusterrole이나 role의 이름을 넣어주면 해당 권한만을 가지게 되는 것이다.
```
mapUsers: |
  - userarn: "arn:aws:iam::686820597897:user/user1"
    username: user1
    groups:
    - system:masters
```
- 현재 어떤 IAM으로 접근하고 있는지는 다음 명령으로 확인할 수 있다.
```
❯ aws sts get-caller-identity --no-cli-pager
{
    "UserId": "AIDAZ72NSUCEQT52YGJKF",
    "Account": "686820597897",
    "Arn": "arn:aws:iam::686820597897:user/user1"
}
```

# fargateProfile
EKS 의 Fargate라는 제품을 사용하는 것이고 서버리스이다. env: dev인 레이블로 만들게 되면 노드 없이도 파드를 띄울 수 있게 된다. 인스턴스 조차 관리할 필요가 없기 때문에 이런 것을 완전 관리형이라고 한다.

- 아래의 경우 레이블이 해당하지 않기 때문에 일반 노드에 파드가 생성된다.
```
❯ cat fargate-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
  namespace: dev
  labels:
    env: prod
spec:
  containers:
    - name: myapp
      image: nginx
```

```
❯ kubectl create -f fargate-pod.yaml
pod/mypod created
❯ kubectl get pods -n dev -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP               NODE                                                NOMINATED NODE   READINESS GATES
mypod   1/1     Running   0          31s   192.168.159.59   ip-192-168-139-83.ap-northeast-2.compute.internal   <none>           <none>
```

- fargateProfile에 맞는 레이블로 파드를 생성하면 다르게 동작하게 된다. 이 경우 경량의 vm만 생성하고 거기에 파드만 띄우는 것
```
❯ cat fargate-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
  namespace: dev
  labels:
    env: dev
spec:
  containers:
    - name: myapp
      image: nginx
❯ kubectl create -f fargate-pod.yaml
pod/mypod created
❯ kubectl get pods -n dev -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE                                READINESS GATES
mypod   0/1     Pending   0          10s   <none>   <none>   1a84c6d517-e1ebbb4500e24ead8ffdebbf3515a416   <none>
```
- nominated node인 상태가 되어 pending인 상태에서 이후에 새로운 노드가 생기고 그곳에 파드가 배치된다. 이것이 바로 경량의 vm이 생기게 되는 것이다.
```
❯ kubectl get pods -n dev -o wide
NAME    READY   STATUS    RESTARTS   AGE     IP                NODE                                                         NOMINATED NODE   READINESS GATES
mypod   1/1     Running   0          2m13s   192.168.191.115   fargate-ip-192-168-191-115.ap-northeast-2.compute.internal   <none>           <none>
❯ kubectl get nodes
NAME                                                         STATUS   ROLES    AGE    VERSION
fargate-ip-192-168-191-115.ap-northeast-2.compute.internal   Ready    <none>   39s    v1.24.9-eks-300e41d
ip-192-168-139-83.ap-northeast-2.compute.internal            Ready    <none>   4h1m   v1.24.10-eks-48e63af
```

- 노드를 실질적으로 사용하는 것이 아니기 때문에 데몬셋을 사용할 수 없다.

NLB나 ALB를 만들 때 IP target이나 Instance target을 정하게 되는데 Instance target으로 하는 경우 파드가 EC2 instance에 떠있어야 한다. fargate로 생성하는 경우 파드가 EC2 인스턴스에 뜨는 것이 아니기 때문에 IP target으로 맞춰줘야 한다. 

fargate로 파드를 생성하는 경우 리소스는 해당 파드의 어노테이션에서 확인가능하다. fargate는 cpu와 memory 시간당으로 요금이 부과된다. [사용할 수 있는 파드 리소스](https://docs.aws.amazon.com/eks/latest/userguide/fargate-pod-configuration.html) 에 따라서 파드 리소스가 지정되기 때문에 리퀘스트나 리밋에 지정을 하더라도 aws에서 제공하는 형태로 리소스가 지정된다. 